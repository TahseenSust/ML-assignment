{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1jR4pmRoYJ4PrUXcNyGwKYd9ifPGLPJve",
      "authorship_tag": "ABX9TyPfpze0UrWd3f11RIuisOJa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TahseenSust/ML-assignment/blob/main/labFinal/MLLab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "L-vkn6HgZUk-"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "shutil.unpack_archive(\"/content/drive/MyDrive/Colab Notebooks/datasetofAI/CNN_dataset.zip\", \"/content/CNN_dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the path to the dataset\n",
        "data_dir = '/content/CNN_dataset/CNN_dataset'\n",
        "\n",
        "# Define the parameters for the ImageDataGenerator\n",
        "batch_size = 32\n",
        "img_height = 64\n",
        "img_width = 64\n",
        "\n",
        "# Create a list of all the image file paths and their corresponding labels\n",
        "file_paths = []\n",
        "labels = []\n",
        "for label in os.listdir(data_dir):\n",
        "    label_dir = os.path.join(data_dir, label)\n",
        "    if not os.path.isdir(label_dir): continue\n",
        "    for img_file in os.listdir(label_dir):\n",
        "        img_path = os.path.join(label_dir, img_file)\n",
        "        file_paths.append(img_path)\n",
        "        labels.append(label)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "train_file_paths, test_file_paths, train_labels, test_labels = train_test_split(\n",
        "    file_paths,\n",
        "    labels,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=labels\n",
        ")\n",
        "\n",
        "# Split the training set into training and validation sets\n",
        "train_file_paths, val_file_paths, train_labels, val_labels = train_test_split(\n",
        "    train_file_paths,\n",
        "    train_labels,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=train_labels\n",
        ")\n",
        "\n",
        "# Create directories for the training, validation, and test sets\n",
        "train_dir = '/content/train'\n",
        "val_dir = '/content/val'\n",
        "test_dir = '/content/test'\n",
        "for dir_name in [train_dir, val_dir, test_dir]:\n",
        "    if os.path.exists(dir_name):\n",
        "        shutil.rmtree(dir_name)\n",
        "    if not os.path.exists(dir_name):\n",
        "        os.makedirs(dir_name)\n",
        "# Copy the training/validation/testing images to the training directory\n",
        "for paths, labels, dir in [(train_file_paths, train_labels, train_dir), (val_file_paths, val_labels, val_dir), (test_file_paths, test_labels, test_dir)]:\n",
        "    for file_path, label in zip(paths, labels):\n",
        "        img_file = os.path.basename(file_path)\n",
        "        label_dir = os.path.join(dir, label)\n",
        "        if not os.path.exists(label_dir):\n",
        "            os.makedirs(label_dir)\n",
        "        shutil.copyfile(file_path, os.path.join(label_dir, img_file))"
      ],
      "metadata": {
        "id": "4pHTD3draVkf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Define the dataset path\n",
        "dataset_path = \"path/to/dataset\"\n",
        "\n",
        "# Define the image size and batch size\n",
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "# Split the dataset into training, validation, and testing sets\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=20,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/train',\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    '/content/val',\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    '/content/test',\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axkidID6a5Cm",
        "outputId": "03056947-01ee-48a5-d4a2-6950a2c32ba8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 30000 images belonging to 5 classes.\n",
            "Found 10000 images belonging to 5 classes.\n",
            "Found 10000 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_size[0], img_size[1], 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(5, activation='softmax'))\n"
      ],
      "metadata": {
        "id": "bAwQdsKYbnGx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "bRHXiqNCbyJF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch=train_generator.samples // batch_size,\n",
        "                    epochs=2,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=validation_generator.samples // batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UQXTIgkb-GK",
        "outputId": "04b3655e-4ba0-47ca-bdc3-8ddbd8074069"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "937/937 [==============================] - 396s 410ms/step - loss: 0.1573 - accuracy: 0.9419 - val_loss: 0.0289 - val_accuracy: 0.9902\n",
            "Epoch 2/2\n",
            "937/937 [==============================] - 385s 411ms/step - loss: 0.0329 - accuracy: 0.9891 - val_loss: 0.0053 - val_accuracy: 0.9976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_generator, verbose=2)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idKGr9zBb9HZ",
        "outputId": "c8e4a99e-b50d-4c10-9157-4e5f5af0f827"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 13s - loss: 0.0067 - accuracy: 0.9971 - 13s/epoch - 43ms/step\n",
            "Test accuracy: 0.9970999956130981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oWC1V26ScCV6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}